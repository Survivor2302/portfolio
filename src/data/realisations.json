{
  "vidibio": {
    "titre": "Vidibio",
    "img": "/images/logo/inria.jpg",
    "previewPicture": "/images/mockup/vidibio.png",
    "preview": "Application mobile innovante pour scanner et analyser les haies agricoles, développée en collaboration avec une startup agritech pour promouvoir une agriculture durable.",
    "description": "Vidibio est une application mobile qui permet de scanner des haies et de collecter des données détaillées sur la biodiversité et la biomasse.",
    "content": {
      "definition": "Vidibio représente une innovation majeure dans le domaine de l'agrotechnologie, combinant technologies mobiles et préoccupations environnementales. Cette application de scanning des haies agricoles illustre parfaitement l'intersection entre développement logiciel et agriculture durable. Le projet s'inscrit dans une démarche globale de transformation numérique du secteur agricole, où la collecte et l'analyse de données environnementales deviennent essentielles pour optimiser les pratiques agricoles tout en préservant la biodiversité.\n\nDans un contexte où l'agriculture fait face à de nombreux défis environnementaux, des solutions comme Vidibio offrent aux agriculteurs et techniciens agricoles des outils précis pour mesurer l'impact de leurs pratiques. L'application permet non seulement de cartographier les haies mais aussi d'évaluer leur contribution à la biodiversité locale et leur potentiel en termes de biomasse. Ces informations, autrefois difficiles à obtenir, deviennent accessibles directement sur le terrain grâce aux technologies mobiles et à la réalité augmentée.\n\nLa qualité des données environnementales et leur accessibilité constituent aujourd'hui des enjeux majeurs pour une agriculture plus responsable. En facilitant la collecte et l'analyse de ces données, Vidibio contribue directement à l'émergence d'une agriculture plus précise, plus efficace et plus respectueuse de l'environnement.",
      "exemplesConcrets": {
        "Cartographie interactive": "L'une des fonctionnalités phares de Vidibio était sa carte interactive développée avec Mapbox. Cette carte permettait de visualiser l'ensemble des haies scannées sur le territoire, avec pour chacune des informations détaillées sur sa composition, sa biodiversité et son potentiel biomasse. Les utilisateurs pouvaient interagir avec la carte en zoomant sur des zones spécifiques, en filtrant les haies selon différents critères, ou en sélectionnant une haie pour obtenir des informations détaillées. La carte s'enrichissait au fur et à mesure des scans réalisés par les utilisateurs, créant ainsi une base de données collaborative et évolutive des haies agricoles.\n\nPour implémenter cette fonctionnalité, j'ai dû travailler sur l'intégration de Mapbox avec React Native, la gestion des données géospatiales, et la création d'une interface utilisateur intuitive permettant d'interagir efficacement avec la carte. J'ai également développé un système de mise à jour en temps réel des données cartographiques, permettant aux utilisateurs de voir les modifications apportées par d'autres utilisateurs sans avoir à recharger l'application.",
        "Scanning avec réalité augmentée": "Le cœur de l'application Vidibio reposait sur sa fonctionnalité de scanning des haies utilisant la réalité augmentée. Grâce à l'intégration d'ARCore, l'application permettait aux utilisateurs de scanner une haie en temps réel, en visualisant directement sur leur écran les zones déjà scannées et celles restant à scanner. Le système calculait automatiquement la longueur, la hauteur et le volume de la haie, tout en identifiant les espèces végétales présentes grâce à un algorithme de reconnaissance basé sur l'intelligence artificielle.\n\nPour développer cette fonctionnalité, j'ai dû approfondir mes connaissances en réalité augmentée et en traitement d'image. J'ai travaillé sur l'optimisation des performances pour garantir une expérience fluide même sur des appareils mobiles aux capacités limitées. J'ai également collaboré avec des experts en biodiversité pour affiner l'algorithme de reconnaissance des espèces végétales, afin d'obtenir des résultats aussi précis que possible.",
        "Analyse de biodiversité": "Vidibio ne se contentait pas de collecter des données sur les haies, mais proposait également des analyses poussées sur la biodiversité qu'elles abritent. À partir des données collectées lors du scanning (espèces végétales, densité, âge des plants), l'application générait un rapport détaillé sur la valeur écologique de la haie, son potentiel d'accueil pour la faune locale, et proposait des recommandations pour améliorer sa contribution à la biodiversité.\n\nLe développement de cette fonctionnalité a nécessité une collaboration étroite avec des biologistes et des écologues, pour traduire leurs connaissances en algorithmes d'analyse pertinents. J'ai créé un moteur d'analyse capable de croiser différentes sources de données (espèces présentes, configuration de la haie, contexte environnemental) pour générer des évaluations précises et des recommandations adaptées à chaque situation."
      },
      "autocritique": "Le développement de Vidibio m'a permis d'atteindre un niveau avancé dans plusieurs domaines techniques, notamment le développement mobile avec React Native, l'intégration de technologies de réalité augmentée, et la gestion de données géospatiales. J'ai également considérablement renforcé mes compétences en matière d'architecture logicielle, ayant dû concevoir un système capable de fonctionner efficacement à la fois en mode connecté et hors-ligne, tout en garantissant la synchronisation des données lorsque la connexion était rétablie.\n\nCependant, je reconnais que certains aspects du projet auraient pu être améliorés. L'algorithme de reconnaissance des espèces végétales, bien que fonctionnel, n'atteignait pas le niveau de précision initialement espéré, particulièrement dans des conditions de luminosité difficiles ou pour certaines espèces très similaires. Avec plus de temps et de ressources, j'aurais souhaité affiner cet algorithme en utilisant des techniques d'apprentissage profond plus avancées et en constituant une base d'apprentissage plus large.\n\nPar ailleurs, l'optimisation des performances de l'application sur les appareils d'entrée de gamme s'est révélée particulièrement complexe. Les fonctionnalités de réalité augmentée et de traitement d'image en temps réel étaient gourmandes en ressources, ce qui pouvait entraîner des ralentissements sur certains appareils. Une approche plus modulaire, adaptant dynamiquement les fonctionnalités activées en fonction des capacités de l'appareil, aurait probablement permis d'offrir une expérience plus fluide à tous les utilisateurs.\n\nEnfin, bien que le backend développé avec Django et FastAPI répondait aux besoins du projet, j'ai réalisé a posteriori que certains choix d'architecture auraient pu être optimisés pour améliorer la scalabilité du système. L'expérience acquise sur ce projet m'a permis de mieux comprendre les enjeux liés à la conception d'API performantes et évolutives, compétences que je continue à développer dans mes projets ultérieurs.",
      "evolution": "Suite à cette expérience enrichissante avec Vidibio, je souhaite continuer à approfondir mes compétences à l'intersection du développement logiciel et des problématiques environnementales. Je m'intéresse particulièrement à l'évolution des technologies de reconnaissance d'image et d'intelligence artificielle appliquées à l'écologie, domaines en constante évolution qui ouvrent des possibilités fascinantes pour la collecte et l'analyse de données environnementales.\n\nÀ court terme, je prévois de me former davantage sur les frameworks d'apprentissage profond comme TensorFlow et PyTorch, afin de pouvoir développer des modèles de reconnaissance plus précis et plus efficaces. Je souhaite également approfondir mes connaissances en matière d'optimisation pour appareils mobiles, notamment en explorant les possibilités offertes par les nouvelles puces dédiées à l'IA présentes dans les smartphones récents.\n\nÀ plus long terme, je vise à acquérir une expertise dans le domaine de la visualisation de données environnementales, en explorant des technologies comme WebGL et Three.js pour créer des représentations 3D interactives de données écologiques complexes. Je suis convaincu que la visualisation joue un rôle clé dans la compréhension et la communication des enjeux environnementaux, et souhaite contribuer à développer des outils toujours plus intuitifs et informatifs dans ce domaine.\n\nEnfin, cette expérience m'a ouvert les yeux sur l'importance de la collaboration interdisciplinaire dans le développement de solutions technologiques pour l'environnement. À l'avenir, je souhaite travailler plus étroitement encore avec des experts de domaines variés (écologues, biologistes, agriculteurs) pour développer des outils véritablement adaptés à leurs besoins et à la complexité des systèmes naturels."
    },
    "associatedCompetences": {
      "techniques": ["kubernetes", "docker"],
      "humaines": ["autonomie", "adaptabilite"]
    }
  },
  "gava": {
    "titre": "Gava",
    "img": "/images/logo/gava.png",
    "previewPicture": "/images/mockup/gava.png",
    "preview": "Plateforme web combinant l'organisation de tournois de jeux vidéo avec la sensibilisation au cyberharcèlement, développée en partenariat avec la Maison de Protection des Familles.",
    "description": "Gava est une application web développée en Java et Angular permettant d'organiser et de gérer des tournois de jeux vidéo, tout en intégrant une section dédiée à la sensibilisation au cyberharcèlement.",
    "content": {
      "definition": "Gava représente une innovation sociale unique combinant deux univers rarement associés : les tournois de jeux vidéo et la prévention du cyberharcèlement. Cette plateforme web illustre comment les technologies peuvent être mises au service de causes sociétales importantes tout en offrant un environnement ludique et attractif pour le public cible. Dans un contexte où le cyberharcèlement touche de plus en plus de jeunes et où les jeux vidéo occupent une place centrale dans leur quotidien, Gava propose une approche novatrice pour sensibiliser sans stigmatiser.\n\nLe développement de plateformes comme Gava répond à un enjeu majeur pour les institutions publiques et associations travaillant avec la jeunesse : trouver des canaux de communication adaptés et efficaces pour transmettre des messages de prévention. L'originalité de cette approche réside dans sa capacité à attirer un public difficile à toucher par les canaux traditionnels de sensibilisation, en utilisant comme point d'entrée une activité qui les passionne.\n\nAu-delà de son aspect social, Gava illustre également l'importance croissante des compétences en développement web dans la mise en œuvre de projets à impact social. La plateforme combine une architecture technique robuste avec une expérience utilisateur soigneusement conçue pour répondre aux attentes d'un public jeune et connecté. Cette double exigence technique et ergonomique fait de Gava un exemple parfait de l'évolution des applications web modernes, qui doivent allier performance, accessibilité et engagement utilisateur.",
      "exemplesConcrets": {
        "Système de tournois": "Le cœur de Gava est son système avancé de gestion de tournois, permettant aux utilisateurs de créer, rejoindre et participer à des compétitions de jeux vidéo. Cette fonctionnalité comprend un générateur automatique d'arbres de tournoi, qui s'adapte au nombre de participants et au format choisi (élimination directe, double élimination, poules suivies de phases finales, etc.). Les organisateurs peuvent personnaliser de nombreux paramètres : règles spécifiques, systèmes de points, durée des matchs, et même intégrer des streams Twitch pour retransmettre les rencontres importantes.\n\nLe développement de cette fonctionnalité a nécessité une conception soigneuse de la base de données pour gérer efficacement les relations entre tournois, équipes, joueurs et matchs, ainsi qu'un algorithme complexe pour la génération et la mise à jour des arbres de tournoi. La mise en place d'un système de notifications en temps réel a également été implémentée pour informer les joueurs des changements d'horaires, des résultats, et des matchs à venir.",
        "Interface d'administration des sponsors": "En tant que développeur sur ce projet, j'ai conçu l'interface d'administration des sponsors, un aspect crucial pour la viabilité à long terme de la plateforme. Cette interface permet aux administrateurs d'ajouter facilement de nouveaux sponsors, de définir leur niveau de partenariat (principal, officiel, technique), d'uploader leurs logos et de spécifier leur visibilité sur les différentes pages du site. Un système de statistiques avancé a également été mis en place pour mesurer la visibilité de chaque sponsor (nombre d'impressions, clics sur les logos).\n\nLe développement de cette fonctionnalité a impliqué la création d'un back-office intuitif, optimisé pour simplifier la gestion des partenariats par des utilisateurs non-techniques. J'ai accordé une attention particulière à l'expérience utilisateur, en implémentant des fonctionnalités comme le glisser-déposer pour réorganiser l'ordre d'affichage des sponsors, et des aperçus en temps réel des modifications avant publication.",
        "Section de sensibilisation au cyberharcèlement": "La section dédiée à la sensibilisation au cyberharcèlement constitue l'élément différenciant de Gava par rapport aux autres plateformes de tournois. Cette section propose des contenus éducatifs adaptés au public jeune : témoignages vidéo, quiz interactifs, fiches pratiques sur la sécurité en ligne, et même un simulateur de situations permettant aux utilisateurs de s'entraîner à réagir face à différents scénarios de cyberharcèlement. Un forum modéré permet également aux utilisateurs d'échanger sur leurs expériences et de poser des questions à des professionnels.\n\nPour développer cette section, nous avons travaillé en étroite collaboration avec des psychologues et des experts du cyberharcèlement afin de créer des contenus pertinents et efficaces. Sur le plan technique, l'intégration de contenus multimédias variés (vidéos, animations, jeux interactifs) a nécessité un travail approfondi sur l'optimisation des performances et l'accessibilité, pour garantir une expérience fluide sur tous les appareils."
      },
      "autocritique": "Le projet Gava m'a permis de progresser significativement dans mes compétences de développement web, particulièrement dans la création d'interfaces utilisateur interactives et la gestion de systèmes complexes comme les tournois. L'utilisation d'Angular pour le frontend m'a donné l'opportunité d'approfondir ma maîtrise de ce framework et d'explorer des fonctionnalités avancées comme les services de communication en temps réel et les formulaires réactifs.\n\nCependant, avec le recul, je constate certaines limitations dans notre approche. La gestion de l'arbre de tournoi, notamment, s'est révélée plus complexe que prévu, particulièrement pour les formats impliquant des phases de poules suivies d'élimination directe. Notre solution fonctionnait, mais manquait de flexibilité pour s'adapter à des cas particuliers comme les forfaits d'équipes ou les changements de dernière minute. Une approche plus modulaire, avec une meilleure séparation entre la logique de gestion des tournois et l'interface utilisateur, aurait probablement facilité les évolutions futures du système.\n\nUn autre point d'amélioration concerne l'optimisation des performances. Au fil du développement, l'accumulation de fonctionnalités a progressivement alourdi l'application, entraînant des temps de chargement parfois trop longs, particulièrement sur les connexions mobiles. Une attention plus soutenue à l'optimisation dès les premières phases du projet, notamment par la mise en place de stratégies de lazy loading et de techniques de mise en cache plus avancées, aurait permis d'offrir une expérience utilisateur plus fluide.\n\nEnfin, bien que notre approche agile ait généralement bien fonctionné, certaines phases de développement auraient bénéficié d'une documentation plus rigoureuse, particulièrement concernant l'API et les intégrations avec des services tiers. Cette lacune s'est fait sentir lors des dernières semaines du projet, quand nous avons dû intégrer rapidement de nouvelles fonctionnalités demandées par le client.",
      "evolution": "Suite à cette expérience enrichissante avec Gava, je souhaite approfondir mes compétences dans plusieurs domaines clés du développement web moderne. À court terme, je vais me concentrer sur l'optimisation des performances des applications Angular, en étudiant des techniques avancées comme le server-side rendering, la gestion intelligente du state management, et l'optimisation des assets. Ces compétences me permettront de créer des applications plus réactives et plus efficaces, offrant une meilleure expérience utilisateur même sur des connexions limitées.\n\nJe prévois également d'explorer plus en profondeur le domaine de l'accessibilité web, un aspect que nous n'avons pas suffisamment priorisé dans Gava. Rendre les applications web pleinement accessibles aux personnes en situation de handicap est non seulement une obligation légale croissante mais aussi un enjeu éthique important. Je souhaite intégrer systématiquement les bonnes pratiques d'accessibilité dans mes futurs projets, en suivant des formations spécialisées et en utilisant des outils d'audit comme Lighthouse et Axe.\n\nÀ moyen terme, je m'intéresse particulièrement à l'évolution des architectures front-end, notamment l'approche micro-frontends qui permet de développer, tester et déployer des parties d'une application de manière indépendante. Cette approche aurait été particulièrement pertinente pour un projet comme Gava, avec ses modules bien distincts (tournois, sensibilisation, administration). J'envisage d'expérimenter avec des frameworks comme Single-SPA ou Module Federation de Webpack pour approfondir cette approche.\n\nEnfin, cette expérience m'a sensibilisé à l'importance de l'impact social des technologies que nous développons. Je souhaite continuer à travailler sur des projets qui, comme Gava, utilisent la technologie comme vecteur de changement social positif. Je prévois de me rapprocher d'associations et d'institutions travaillant sur des problématiques sociales (cyberharcèlement, inclusion numérique, éducation) pour proposer mes compétences techniques au service de leurs missions."
    },
    "associatedCompetences": {
      "techniques": ["java", "git"],
      "humaines": ["pensee", "flexibilite"]
    }
  },
  "optivex": {
    "titre": "Optivex",
    "img": "/images/logo/optivex.jpg",
    "previewPicture": "/images/mockup/optivex.png",
    "preview": "Application mobile de digitalisation du suivi des livraisons pour UPSA, transformant un processus papier en solution numérique efficace et écologique.",
    "description": "Optivex est une application mobile développée pour UPSA permettant de digitaliser et centraliser le suivi des livraisons de matières premières, remplaçant un système papier inefficace.",
    "content": {
      "definition": "Optivex illustre parfaitement la digitalisation des processus industriels traditionnels, un enjeu majeur pour les entreprises cherchant à optimiser leurs opérations tout en réduisant leur impact environnemental. Cette application mobile de suivi des livraisons représente la transformation numérique appliquée à la chaîne logistique, domaine où la précision et la traçabilité des informations sont cruciales. Dans le secteur pharmaceutique en particulier, la gestion rigoureuse des approvisionnements en matières premières constitue un élément fondamental pour garantir la qualité et la conformité des produits finis.\n\nLa transition des systèmes papier vers des solutions numériques comme Optivex répond à plusieurs besoins essentiels des entreprises modernes. D'une part, elle permet d'éliminer les erreurs liées à la saisie manuelle des données et aux documents papier (pertes, illisibilité, retranscriptions erronées). D'autre part, elle facilite considérablement l'analyse et l'exploitation des données collectées, offrant ainsi de nouvelles perspectives d'optimisation des processus logistiques.\n\nAu-delà des aspects purement opérationnels, la digitalisation des processus s'inscrit également dans une démarche de responsabilité environnementale. En réduisant la consommation de papier et en optimisant les flux logistiques grâce à une meilleure exploitation des données, des applications comme Optivex contribuent directement à la réduction de l'empreinte écologique des entreprises industrielles. Cette double dimension, alliant efficacité opérationnelle et préoccupations environnementales, illustre parfaitement l'évolution du développement applicatif métier vers des solutions plus durables et responsables.",
      "exemplesConcrets": {
        "Interface de sélection des camions": "La première page du formulaire d'Optivex, que j'ai personnellement développée, permet aux livreurs de sélectionner rapidement le camion utilisé pour la livraison. Cette interface présente une liste des véhicules fréquemment utilisés, avec leurs caractéristiques principales (immatriculation, capacité, type) et une photo pour faciliter l'identification. Pour les cas exceptionnels, un système de recherche avancée permet de trouver un véhicule spécifique dans la base de données complète, ou d'ajouter temporairement un nouveau véhicule non répertorié.\n\nLe développement de cette interface a nécessité une attention particulière à l'ergonomie mobile, en tenant compte des contraintes d'utilisation sur le terrain (gants, luminosité variable, temps limité). J'ai implémenté une interface tactile optimisée avec de larges boutons et une navigation intuitive, ainsi qu'un système de mise en cache permettant aux utilisateurs fréquents de retrouver rapidement leurs véhicules habituels. Le code a été structuré selon le pattern Model-View-Presenter pour faciliter la testabilité et la maintenance future.",
        "Formulaire de détails de livraison": "La seconde page du formulaire, également développée par mes soins, est l'élément central d'Optivex. Elle permet de saisir l'ensemble des informations relatives à une livraison : heure de départ, trajet effectué, matériaux livrés (avec leurs références et quantités), heure d'arrivée, entreprise de transport, et commentaires éventuels. Le formulaire intègre de nombreuses validations en temps réel pour garantir la qualité des données : vérification des références de matériaux contre la base de données UPSA, calcul automatique des durées, contrôle de cohérence des horaires, etc.\n\nPour développer cette fonctionnalité, j'ai dû concevoir un système de formulaire dynamique capable de s'adapter aux différents types de livraisons et de matériaux. J'ai implémenté un mécanisme de sauvegarde automatique des données en cours de saisie pour éviter toute perte d'information en cas d'interruption. L'interface utilise des composants natifs Android optimisés pour la saisie mobile (sélecteurs d'heure, menus déroulants contextuels, saisie assistée) tout en maintenant une cohérence visuelle avec les standards UPSA.",
        "Système d'exportation CSV": "Le système d'exportation des données au format CSV constitue un élément crucial d'Optivex, assurant l'intégration avec les systèmes existants d'UPSA. Cette fonctionnalité permet de générer des fichiers CSV structurés selon les spécifications précises requises par les différents services (logistique, qualité, comptabilité). Les utilisateurs peuvent sélectionner la période à exporter, filtrer les données selon divers critères (transporteur, type de matériau, site de livraison), et choisir le format de sortie adapté à leur besoin.\n\nLe développement de ce système a nécessité une compréhension approfondie des exigences des différents départements d'UPSA concernant le format et la structure des données. J'ai implémenté un moteur d'exportation flexible, capable de générer différentes structures de fichiers CSV selon le contexte d'utilisation. Un système de validation préalable des données garantit que seules des informations complètes et cohérentes sont exportées, évitant ainsi les problèmes lors de l'importation dans les systèmes tiers."
      },
      "autocritique": "Le développement d'Optivex m'a permis de renforcer considérablement mes compétences en développement mobile natif avec Java et Android Studio. J'ai particulièrement progressé dans la conception d'interfaces adaptées aux contraintes d'utilisation sur le terrain, un aspect crucial pour les applications professionnelles mobiles. Le projet m'a également apporté une meilleure compréhension des enjeux liés à la persistance des données sur mobile et à la synchronisation avec des systèmes d'information complexes.\n\nCependant, avec le recul, je constate plusieurs aspects qui auraient pu être améliorés. Premièrement, notre approche de la gestion hors-ligne aurait bénéficié d'une architecture plus robuste. Bien que l'application fonctionne sans connexion, certains scénarios particuliers de synchronisation (conflits de données, interruptions pendant le transfert) n'étaient pas gérés de manière optimale. Une implémentation plus sophistiquée utilisant des files de synchronisation et un système de résolution de conflits aurait rendu l'application plus résiliente.\n\nDe plus, l'interface utilisateur, bien que fonctionnelle, aurait pu bénéficier d'une approche plus moderne suivant les principes du Material Design. Notre priorité était la fonctionnalité plutôt que l'esthétique, mais j'ai réalisé par la suite qu'une interface plus soignée aurait probablement amélioré l'adoption et la satisfaction des utilisateurs. L'utilisation de bibliothèques comme AndroidX et des composants architecturaux plus récents aurait également facilité certains aspects du développement.\n\nEnfin, notre approche des tests automatisés était insuffisante. Nous avons principalement réalisé des tests manuels, ce qui a fonctionné pour ce projet de taille moyenne, mais n'aurait pas été soutenable pour un projet plus large ou avec plus d'évolutions. L'intégration de tests unitaires et d'interface utilisateur automatisés dès le début du projet aurait facilité les modifications ultérieures et amélioré la qualité globale du code.",
      "evolution": "Suite à cette expérience enrichissante avec Optivex, je souhaite approfondir plusieurs aspects du développement mobile pour les applications professionnelles. À court terme, je prévois d'explorer les architectures modernes de développement Android, particulièrement les modèles MVVM (Model-View-ViewModel) avec Android Architecture Components et le flux de données réactif avec Kotlin Flow ou RxJava. Ces approches permettent de créer des applications plus maintenables et testables, avec une séparation claire des responsabilités.\n\nJe compte également me former aux dernières évolutions de Jetpack Compose, la nouvelle boîte à outils d'interface utilisateur déclarative pour Android. Cette technologie simplifie considérablement le développement d'interfaces complexes et interactives, tout en améliorant les performances et la testabilité. Son adoption croissante dans l'écosystème Android en fait une compétence essentielle pour les développements futurs.\n\nSur le plan méthodologique, je souhaite approfondir mes connaissances en matière de développement piloté par les tests (TDD) pour les applications mobiles. Cette approche, qui consiste à écrire les tests avant le code de production, permet de garantir une meilleure qualité logicielle et facilite les évolutions futures. J'envisage de suivre des formations spécifiques sur ce sujet et de l'appliquer systématiquement dans mes prochains projets.\n\nÀ plus long terme, je m'intéresse au développement cross-platform avec des technologies comme Flutter ou React Native. Bien que le développement natif offre des avantages indéniables en termes de performances et d'accès aux fonctionnalités avancées du système, les solutions cross-platform ont considérablement mûri ces dernières années et offrent un excellent compromis pour de nombreux cas d'usage. Acquérir ces compétences me permettrait de choisir l'approche la plus adaptée en fonction des contraintes spécifiques de chaque projet."
    },
    "associatedCompetences": {
      "techniques": ["java"],
      "humaines": ["anglais", "pensee"]
    }
  },
  "todoapp": {
    "titre": "TodoApp",
    "img": "/images/logo/todoapp.png",
    "previewPicture": "/images/mockup/todoapp.png",
    "preview": "Application cross-platform de gestion de tâches avancée, offrant synchronisation en temps réel, analyses de productivité et une expérience utilisateur personnalisable.",
    "description": "TodoApp est une application mobile et web développée avec Ionic React et TypeScript, offrant une gestion avancée de tâches avec synchronisation cross-platform, catégorisation et analyses de productivité.",
    "content": {
      "definition": "TodoApp représente l'évolution moderne des outils de gestion de tâches, combinant interfaces multi-plateformes, synchronisation en temps réel et analyses avancées de productivité. Ce projet illustre la tendance croissante des applications personnelles à adopter des fonctionnalités traditionnellement réservées aux outils professionnels, tout en conservant une expérience utilisateur simple et intuitive. Dans un monde où la frontière entre vie professionnelle et personnelle devient de plus en plus floue, des applications comme TodoApp répondent au besoin de solutions unifiées pour gérer efficacement l'ensemble de nos responsabilités quotidiennes.\n\nLe développement d'applications cross-platform comme TodoApp est devenu essentiel dans un écosystème numérique fragmenté entre différents appareils et systèmes d'exploitation. L'approche hybride, utilisant des frameworks comme Ionic React, permet de créer des expériences cohérentes sur web, iOS et Android, tout en optimisant les coûts et délais de développement. Cette stratégie technique reflète l'évolution du développement applicatif vers des solutions plus agiles et adaptatives.\n\nAu-delà de l'aspect technique, TodoApp s'inscrit dans la tendance plus large des applications conçues pour améliorer la productivité et le bien-être personnel. L'intégration d'analyses de données et de visualisations permet aux utilisateurs de mieux comprendre leurs habitudes de travail et d'identifier les opportunités d'amélioration. Cette dimension analytique transforme un simple outil de gestion de tâches en un véritable assistant personnel pour l'optimisation du temps et des efforts.",
      "exemplesConcrets": {
        "Système de tâches hiérarchiques": "L'une des fonctionnalités distinctives de TodoApp est son système de tâches hiérarchiques, permettant aux utilisateurs de décomposer des projets complexes en tâches et sous-tâches imbriquées sur plusieurs niveaux. Chaque niveau peut avoir ses propres paramètres de priorité, dates d'échéance et statuts, tout en maintenant une relation logique avec les niveaux supérieurs et inférieurs. Le système calcule automatiquement la progression des tâches parentes en fonction de l'avancement des sous-tâches, offrant ainsi une vision claire de l'état global des projets.\n\nPour développer cette fonctionnalité, j'ai implémenté une structure de données arborescente optimisée pour les opérations récursives, avec un système de mise à jour en cascade qui propage les changements à travers la hiérarchie. J'ai également créé une interface utilisateur intuitive permettant d'ajouter, de réorganiser et de modifier facilement les tâches à différents niveaux, en utilisant des techniques de glisser-déposer et d'animation pour rendre l'interaction fluide et naturelle.",
        "Tableau de bord analytique": "Le tableau de bord analytique de TodoApp offre aux utilisateurs des visualisations détaillées de leur productivité et de leurs habitudes de travail. Il présente différentes métriques comme le taux de complétion des tâches par jour/semaine/mois, le temps moyen nécessaire pour finaliser des tâches par catégorie, les heures du jour les plus productives, et l'évolution de la charge de travail au fil du temps. Ces données sont présentées sous forme de graphiques interactifs permettant aux utilisateurs d'explorer leurs tendances personnelles et d'identifier des opportunités d'amélioration.\n\nLe développement de cette fonctionnalité a nécessité la mise en place d'un système sophistiqué de collecte et d'analyse de données, capturant discrètement les interactions de l'utilisateur sans perturber son expérience. J'ai intégré des bibliothèques de visualisation comme Chart.js, que j'ai adaptées pour fonctionner efficacement dans un environnement Ionic React avec des contraintes de taille d'écran variables. Une attention particulière a été portée à l'optimisation des performances, notamment pour le rendu des graphiques complexes sur des appareils mobiles aux ressources limitées.",
        "Synchronisation cross-platform": "Le système de synchronisation de TodoApp constitue le cœur technique de l'application, permettant aux utilisateurs d'accéder à leurs tâches et de les modifier depuis n'importe quel appareil, avec une mise à jour en temps réel sur tous les autres appareils connectés. Cette fonctionnalité gère intelligemment les conflits potentiels lorsque des modifications sont effectuées simultanément sur différents appareils, et fonctionne également hors-ligne, en enregistrant localement les modifications pour les synchroniser dès qu'une connexion est disponible.\n\nLe développement de cette fonctionnalité a nécessité la mise en place d'une architecture complexe combinant une base de données locale SQLite (via Capacitor) et un système de synchronisation cloud avec Firebase Firestore. J'ai implémenté un mécanisme de résolution de conflits basé sur des horodatages et des identifiants uniques, ainsi qu'un système de file d'attente pour la synchronisation différée des modifications effectuées hors-ligne. La gestion des états de connexion et la récupération après interruption ont constitué des défis particuliers, nécessitant une approche robuste avec des mécanismes de reprise et de vérification de l'intégrité des données."
      },
      "autocritique": "Le développement de TodoApp m'a permis d'acquérir une solide expérience en matière de développement cross-platform avec Ionic React et TypeScript. J'ai particulièrement progressé dans la gestion d'états complexes, la synchronisation de données entre le cloud et le stockage local, et l'optimisation des performances sur différents appareils et plateformes.\n\nCependant, je reconnais plusieurs limitations et points d'amélioration. Premièrement, l'architecture de l'application, bien que fonctionnelle, a évolué de manière organique plutôt que suivant une vision clairement définie dès le départ. Cela a entraîné quelques incohérences dans la structure du code et la gestion des états, particulièrement évidents dans les composants les plus anciens. Une refactorisation utilisant des patterns plus stricts comme le Redux ou le Context API appliqués systématiquement améliorerait la maintenabilité de la codebase.\n\nEnsuite, les performances de l'application sur des appareils d'entrée de gamme restent un défi, particulièrement pour les visualisations graphiques et les listes de tâches très longues. J'ai implémenté plusieurs optimisations (virtualisation des listes, chargement différé, memoization des composants), mais une approche plus fondamentale de l'optimisation des performances dès la conception initiale aurait probablement donné de meilleurs résultats.\n\nEnfin, la couverture des tests automatisés est insuffisante, se concentrant principalement sur les composants critiques et la logique de synchronisation. Une approche plus systématique du test, potentiellement guidée par la méthodologie TDD (Test-Driven Development), aurait non seulement amélioré la qualité et la robustesse du code, mais également facilité les évolutions futures de l'application sans risque de régressions.\n\nMalgré ces limitations, TodoApp reste un projet dont je suis fier, qui m'a permis d'explorer en profondeur les défis spécifiques au développement d'applications cross-platform synchronisées en temps réel.",
      "evolution": "Suite à cette expérience enrichissante avec TodoApp, je souhaite approfondir plusieurs aspects du développement d'applications cross-platform et de la gestion de données synchronisées. À court terme, je prévois d'explorer davantage les architectures de gestion d'état avancées comme Redux Toolkit et les hooks personnalisés de React, pour créer des structures de code plus maintenables et prévisibles. Je m'intéresse également aux performances des applications Ionic, en étudiant les techniques d'optimisation spécifiques comme le Virtual Scroll, le lazy loading des modules, et l'utilisation plus efficace des ressources natives via Capacitor.\n\nJe compte également améliorer mes compétences en matière de tests automatisés pour les applications cross-platform, en explorant des outils comme Cypress pour les tests end-to-end, et en adoptant une approche plus systématique des tests unitaires avec Jest et React Testing Library. Une meilleure couverture de tests permettrait non seulement d'améliorer la qualité du code, mais aussi d'accélérer le cycle de développement en détectant plus rapidement les problèmes potentiels.\n\nÀ moyen terme, je souhaite approfondir ma compréhension des systèmes de synchronisation de données complexes, en étudiant des approches alternatives comme les CRDTs (Conflict-free Replicated Data Types) et les bases de données locales plus avancées comme Realm. Ces technologies permettraient de gérer des scénarios de synchronisation encore plus complexes tout en améliorant les performances et la fiabilité.\n\nEnfin, je m'intéresse de plus en plus à l'intégration de l'intelligence artificielle dans les applications de productivité personnelle. Je prévois d'explorer comment des technologies comme les Large Language Models pourraient être utilisées pour améliorer TodoApp, par exemple en suggérant automatiquement des catégorisations de tâches, en estimant la durée des tâches basée sur l'historique, ou en recommandant des priorités en fonction du contexte de l'utilisateur. Cette direction représente pour moi la prochaine frontière des applications de productivité, où l'intelligence artificielle devient un véritable assistant personnel capable d'apprendre des habitudes de l'utilisateur pour lui offrir des recommandations toujours plus pertinentes."
    },
    "associatedCompetences": {
      "techniques": ["typescript", "git"],
      "humaines": ["autonomie", "adaptabilite"]
    }
  },
  "theseus": {
    "titre": "Theseus",
    "img": "/images/logo/theseus.png",
    "previewPicture": "/images/mockup/theseus.png",
    "preview": "Application web et mobile innovante proposant des services d'enregistrement et de transcription automatique de réunions via Teams, Google Meet, Zoom ou dictaphone, avec analyse IA des conversations pour faciliter la prise de décision.",
    "description": "Theseus est une plateforme complète permettant l'enregistrement et l'analyse automatisée des réunions virtuelles, avec une infrastructure scalable basée sur Kubernetes et des fonctionnalités avancées de traitement audio.",
    "content": {
      "definition": "Theseus incarne l'innovation technologique appliquée aux communications professionnelles modernes, en transformant radicalement la façon dont les entreprises capturent et exploitent le contenu de leurs réunions virtuelles. Dans un contexte où le travail à distance et les réunions en ligne sont devenus la norme, cette plateforme répond au besoin croissant d'outils permettant non seulement d'enregistrer ces échanges mais aussi d'en extraire une valeur ajoutée grâce à l'analyse automatisée du contenu.\n\nLa solution s'inscrit à l'intersection de plusieurs tendances technologiques majeures : l'automatisation des processus métier, l'intelligence artificielle appliquée au langage naturel, et les infrastructures cloud scalables. En permettant l'enregistrement automatique des réunions sur diverses plateformes comme Teams, Google Meet ou Zoom, Theseus élimine la nécessité d'une intervention manuelle tout en garantissant que chaque échange important est capturé, transcrit et analysé.\n\nAu-delà de l'aspect purement technique, Theseus répond à des enjeux organisationnels cruciaux pour les entreprises modernes : amélioration de la prise de décision grâce à des données structurées issues des conversations, réduction du temps consacré aux comptes-rendus manuels, et création d'une mémoire institutionnelle accessible et exploitable. En transformant des flux de paroles éphémères en ressources documentaires permanentes et analysables, cette plateforme s'impose comme un outil stratégique pour les organisations cherchant à optimiser leur communication interne et à capitaliser sur leur intelligence collective.",
      "exemplesConcrets": {
        "Système de bots d'enregistrement": "Au cœur de Theseus se trouve son système sophistiqué de bots d'enregistrement, capable de se connecter automatiquement aux réunions programmées sur différentes plateformes (Teams, Google Meet, Zoom, Zoho). Ces bots, développés avec Puppeteer, simulent un participant humain qui rejoint la réunion, active l'enregistrement audio et vidéo, et capture l'intégralité de la session sans intervention manuelle. Le système gère intelligemment les spécificités de chaque plateforme, s'adaptant à leurs interfaces et protocoles distincts, tout en surmontant les défis liés aux mises à jour fréquentes de ces services.\n\nEn tant que développeur backend sur ce projet, j'ai conçu l'architecture permettant à ces bots de fonctionner de manière fiable et scalable. J'ai implémenté un système de templates pour chaque plateforme, avec des mécanismes de détection et d'adaptation aux changements d'interface. Une couche d'abstraction commune permet de traiter les enregistrements de manière uniforme, indépendamment de leur source. J'ai également développé un système de surveillance en temps réel qui vérifie continuellement le bon fonctionnement des bots, avec des mécanismes de reprise automatique en cas d'échec et des alertes pour les situations nécessitant une intervention humaine.",
        "Infrastructure Kubernetes scalable": "L'infrastructure de Theseus représente un exemple parfait d'architecture cloud-native moderne, basée sur Kubernetes pour orchestrer dynamiquement les ressources nécessaires à chaque enregistrement. Chaque session d'enregistrement s'exécute dans un conteneur isolé avec des ressources dédiées, garantissant performances et fiabilité. Le système scale automatiquement en fonction du nombre d'enregistrements simultanés, provisionnant instantanément les ressources nécessaires et les libérant dès qu'elles ne sont plus requises, optimisant ainsi les coûts d'infrastructure.\n\nJ'ai joué un rôle clé dans la conception et l'implémentation de cette infrastructure, en développant les manifestes Kubernetes, les stratégies de déploiement et les mécanismes d'autoscaling. J'ai mis en place un système de health checks et de readiness probes pour garantir la fiabilité des services, ainsi que des stratégies de redémarrage automatique en cas de défaillance. Un des défis majeurs a été la gestion efficace du stockage temporaire et permanent des enregistrements, que j'ai résolu en implémentant un pipeline de traitement qui transfère les données des volumes éphémères vers AWS S3 dès que possible, avec des mécanismes de vérification d'intégrité et de reprise sur erreur.",
        "Système de diarization et d'analyse": "Le système de diarization (identification des interlocuteurs) et d'analyse conversationnelle constitue la couche d'intelligence de Theseus, transformant les enregistrements bruts en données structurées exploitables. Ce module utilise des algorithmes avancés de traitement du signal et d'apprentissage profond pour segmenter l'audio par locuteur, identifier les participants, et transcrire précisément leurs interventions même dans des conditions audio difficiles (superpositions de voix, bruits de fond). L'analyse sémantique identifie ensuite les sujets abordés, les décisions prises, les questions en suspens, et génère automatiquement un résumé structuré de la réunion.\n\nJ'ai contribué significativement à l'intégration de ces technologies d'IA dans notre pipeline de traitement, en développant l'API qui relie les services de diarization et de transcription aux systèmes de stockage et d'indexation. J'ai implémenté des mécanismes d'optimisation pour traiter efficacement les fichiers audio de longue durée, en utilisant des techniques de segmentation et de traitement parallèle. Un des aspects les plus complexes a été la synchronisation précise entre la transcription texte et l'enregistrement audio original, permettant aux utilisateurs de naviguer facilement entre ces deux représentations."
      },
      "autocritique": "Le développement de Theseus a considérablement renforcé mes compétences en développement backend et en gestion d'infrastructures cloud complexes. J'ai particulièrement progressé dans l'orchestration Kubernetes, l'automatisation via Puppeteer, et l'intégration de services d'IA pour le traitement audio et l'analyse de texte. La conception d'un système capable de gérer des charges variables tout en maintenant une fiabilité maximale a été particulièrement formatrice.\n\nCependant, plusieurs aspects du projet auraient pu être améliorés. La maintenance des bots d'enregistrement s'est révélée plus complexe que prévu, nécessitant des ajustements quasi quotidiens pour s'adapter aux changements d'interface des plateformes de visioconférence. Avec le recul, une approche plus modulaire et déclarative de la définition des interactions avec ces interfaces aurait probablement facilité cette maintenance, par exemple en utilisant un DSL (Domain Specific Language) pour décrire les workflows d'interaction plutôt que de les coder directement en JavaScript.\n\nLa gestion des erreurs et des cas limites constitue un autre domaine d'amélioration potentielle. Bien que nous ayons mis en place des mécanismes robustes pour les scénarios les plus courants, certaines situations exceptionnelles (comme des configurations de réunion atypiques ou des problèmes réseau intermittents) pouvaient encore perturber le fonctionnement des bots. Une approche plus systématique de la détection et du traitement des conditions d'erreur, peut-être inspirée des principes du chaos engineering, aurait renforcé la résilience globale du système.\n\nEnfin, la scalabilité horizontale de notre architecture, bien que fonctionnelle, présentait des limitations en termes d'efficacité d'utilisation des ressources. Le provisionnement d'une machine entière par enregistrement, bien que simplifiant la gestion des ressources, n'était pas optimal pour les enregistrements courts ou peu exigeants. Une granularité plus fine dans l'allocation des ressources, potentiellement via des technologies comme Knative ou AWS Fargate, aurait probablement permis d'optimiser davantage les coûts d'infrastructure.",
      "evolution": "Suite à cette expérience enrichissante avec Theseus, je souhaite approfondir plusieurs aspects du développement backend et de l'architecture cloud. À court terme, je prévois d'explorer davantage les modèles d'architecture serverless et event-driven, qui offrent des avantages significatifs en termes de scalabilité fine et d'optimisation des coûts. Je m'intéresse particulièrement aux services comme AWS Lambda et aux frameworks comme Serverless ou Nest.js intégrant nativement ces concepts.\n\nJe compte également approfondir mes connaissances en matière d'automatisation et de testing des applications web headless. L'expérience avec Puppeteer m'a montré l'importance et la complexité de ce domaine, et je souhaite explorer des approches plus robustes et maintenables, notamment en utilisant des frameworks dédiés comme Playwright qui offrent des capacités avancées de debugging et une meilleure isolation des environnements d'exécution.\n\nDans le domaine de l'infrastructure cloud, je vise à élargir ma maîtrise des pratiques GitOps et Infrastructure as Code, en m'orientant vers des outils comme Argo CD et Terraform pour automatiser davantage le provisionnement et la gestion des ressources cloud. Ces approches permettent non seulement d'améliorer la reproductibilité et la fiabilité des déploiements, mais aussi de faciliter la collaboration entre équipes de développement et d'opérations.\n\nÀ plus long terme, je m'intéresse à l'évolution des technologies d'IA appliquées à l'analyse conversationnelle et au traitement du langage naturel. Les progrès rapides dans ce domaine, avec l'émergence de modèles toujours plus performants comme GPT-4, ouvrent des perspectives fascinantes pour enrichir des plateformes comme Theseus. Je souhaite notamment explorer comment ces technologies pourraient être utilisées pour générer des synthèses plus pertinentes, identifier automatiquement les points d'action, ou même proposer des suggestions en temps réel pendant les réunions.\n\nEnfin, cette expérience a renforcé ma conviction que la fiabilité et la résilience sont des qualités fondamentales pour les systèmes critiques comme Theseus. Je prévois donc d'approfondir mes connaissances en matière d'ingénierie de la fiabilité (SRE), en étudiant les méthodologies et outils permettant de concevoir, mesurer et améliorer la résilience des systèmes distribués complexes."
    },
    "associatedCompetences": {
      "techniques": ["docker", "kubernetes", "typescript"],
      "humaines": ["anglais", "flexibilite"]
    }
  }
}
